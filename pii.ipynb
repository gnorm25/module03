{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [02:54<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4550, Accuracy: 0.7164, F1-Score: 0.6952\n",
      "Best model saved at epoch 1 with validation accuracy: 0.7164\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [03:04<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.3631, Accuracy: 0.6284, F1-Score: 0.6170\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [03:22<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.5884, Accuracy: 0.5482, F1-Score: 0.5371\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [04:23<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.9523, Accuracy: 0.4641, F1-Score: 0.4535\n",
      "Early stopping triggered\n",
      "Best Validation Accuracy: 0.7164\n",
      "Best model loaded from best_model_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27912/1351767038.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제출 파일 생성 완료: submission_5.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir = './train'\n",
    "test_dir = './test'\n",
    "labels_file = './labels.csv'\n",
    "\n",
    "# 라벨 -> 인덱스 변환 및 반대 변환\n",
    "def create_label_mappings(labels_df):\n",
    "    breed_to_idx = {breed: idx for idx, breed in enumerate(sorted(labels_df['breed'].unique()))}\n",
    "    idx_to_breed = {idx: breed for breed, idx in breed_to_idx.items()}\n",
    "    return breed_to_idx, idx_to_breed\n",
    "\n",
    "# 데이터셋 전처리 변환 설정\n",
    "def get_transforms(augment=False):\n",
    "    if augment:\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "# Dataset 클래스 정의\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0] + '.jpg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if not self.is_test:\n",
    "            breed_name = self.dataframe.iloc[idx, 1]\n",
    "            label = breed_to_idx[breed_name]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, self.dataframe.iloc[idx, 0]\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성 함수\n",
    "def create_data_loaders(train_df, val_df, batch_size, img_dir):\n",
    "    train_dataset = DogBreedDataset(dataframe=train_df, img_dir=img_dir, transform=get_transforms(augment=True))\n",
    "    val_dataset = DogBreedDataset(dataframe=val_df, img_dir=img_dir, transform=get_transforms(augment=False))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, early_stop_limit=3, best_model_path='best_model.pth'):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    early_stop_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        # 학습 단계\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # 검증 단계\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # 성능 지표 계산\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')\n",
    "\n",
    "        # 베스트 모델 저장\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            early_stop_count = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f'Best model saved at epoch {epoch+1} with validation accuracy: {accuracy:.4f}')\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "\n",
    "        # 조기 종료 체크\n",
    "        if early_stop_count >= early_stop_limit:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n",
    "\n",
    "# 테스트 데이터셋에 대한 예측\n",
    "def predict_test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predictions.extend(probabilities.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# 제출 파일 생성 함수\n",
    "def create_submission(predictions, idx_to_breed, test_df, output_file):\n",
    "    predictions_df = pd.DataFrame(predictions, columns=idx_to_breed.values())\n",
    "    predictions_df.insert(0, 'id', test_df['id'])\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    print(f\"제출 파일 생성 완료: {output_file}\")\n",
    "\n",
    "# 메인 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    # 레이블 파일 읽기\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "    \n",
    "    # 라벨 -> 인덱스 변환 및 반대 변환\n",
    "    breed_to_idx, idx_to_breed = create_label_mappings(labels_df)\n",
    "\n",
    "    # 데이터셋 분리\n",
    "    train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['breed'], random_state=42)\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader = create_data_loaders(train_df, val_df, batch_size=32, img_dir=train_dir)\n",
    "\n",
    "    # 클래스 가중치 계산\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(labels_df['breed']), y=labels_df['breed'])\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # 사전 훈련된 ResNet50 모델 로드 및 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(breed_to_idx))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 옵티마이저, 스케줄러 및 손실 함수 설정\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=20)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # 베스트 모델 파일 경로 설정\n",
    "    best_model_path = 'best_model_5.pth'\n",
    "\n",
    "    # 모델 학습\n",
    "    model, best_acc = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=20, device=device, best_model_path=best_model_path)\n",
    "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    # 최종 베스트 모델 로드 (저장된 파일에서)\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model = model.to(device)\n",
    "    print(f'Best model loaded from {best_model_path}')\n",
    "\n",
    "    # 테스트 데이터 예측 및 제출 파일 생성\n",
    "    test_df = pd.DataFrame({'id': [f.split('.')[0] for f in os.listdir(test_dir)]})\n",
    "    test_dataset = DogBreedDataset(dataframe=test_df, img_dir=test_dir, transform=get_transforms(augment=False), is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    predictions = predict_test(model, test_loader, device)\n",
    "    create_submission(predictions, idx_to_breed, test_df, output_file='submission_5.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Validation Loss: 4.7443, Accuracy: 0.0323, F1-Score: 0.0206\n",
      "Best model saved at epoch 1 with validation accuracy: 0.0323\n",
      "Epoch 2/20\n",
      "Validation Loss: 4.2662, Accuracy: 0.3320, F1-Score: 0.2986\n",
      "Best model saved at epoch 2 with validation accuracy: 0.3320\n",
      "Epoch 3/20\n",
      "Validation Loss: 1.5744, Accuracy: 0.7178, F1-Score: 0.6953\n",
      "Best model saved at epoch 3 with validation accuracy: 0.7178\n",
      "Epoch 4/20\n",
      "Validation Loss: 1.0081, Accuracy: 0.7467, F1-Score: 0.7365\n",
      "Best model saved at epoch 4 with validation accuracy: 0.7467\n",
      "Epoch 5/20\n",
      "Validation Loss: 0.8008, Accuracy: 0.7702, F1-Score: 0.7609\n",
      "Best model saved at epoch 5 with validation accuracy: 0.7702\n",
      "Epoch 6/20\n",
      "Validation Loss: 0.7651, Accuracy: 0.7619, F1-Score: 0.7536\n",
      "Epoch 7/20\n",
      "Validation Loss: 0.7050, Accuracy: 0.7775, F1-Score: 0.7716\n",
      "Best model saved at epoch 7 with validation accuracy: 0.7775\n",
      "Epoch 8/20\n",
      "Validation Loss: 0.6890, Accuracy: 0.7956, F1-Score: 0.7926\n",
      "Best model saved at epoch 8 with validation accuracy: 0.7956\n",
      "Epoch 9/20\n",
      "Validation Loss: 0.7157, Accuracy: 0.7800, F1-Score: 0.7757\n",
      "Epoch 10/20\n",
      "Validation Loss: 0.6434, Accuracy: 0.8029, F1-Score: 0.8017\n",
      "Best model saved at epoch 10 with validation accuracy: 0.8029\n",
      "Epoch 11/20\n",
      "Validation Loss: 0.6542, Accuracy: 0.8088, F1-Score: 0.8065\n",
      "Best model saved at epoch 11 with validation accuracy: 0.8088\n",
      "Epoch 12/20\n",
      "Validation Loss: 0.6324, Accuracy: 0.8064, F1-Score: 0.8065\n",
      "Epoch 13/20\n",
      "Validation Loss: 0.6296, Accuracy: 0.8093, F1-Score: 0.8089\n",
      "Best model saved at epoch 13 with validation accuracy: 0.8093\n",
      "Epoch 14/20\n",
      "Validation Loss: 0.6215, Accuracy: 0.8117, F1-Score: 0.8107\n",
      "Best model saved at epoch 14 with validation accuracy: 0.8117\n",
      "Epoch 15/20\n",
      "Validation Loss: 0.5907, Accuracy: 0.8200, F1-Score: 0.8182\n",
      "Best model saved at epoch 15 with validation accuracy: 0.8200\n",
      "Epoch 16/20\n",
      "Validation Loss: 0.5877, Accuracy: 0.8210, F1-Score: 0.8199\n",
      "Best model saved at epoch 16 with validation accuracy: 0.8210\n",
      "Epoch 17/20\n",
      "Validation Loss: 0.5834, Accuracy: 0.8269, F1-Score: 0.8258\n",
      "Best model saved at epoch 17 with validation accuracy: 0.8269\n",
      "Epoch 18/20\n",
      "Validation Loss: 0.5701, Accuracy: 0.8259, F1-Score: 0.8253\n",
      "Epoch 19/20\n",
      "Validation Loss: 0.5747, Accuracy: 0.8254, F1-Score: 0.8246\n",
      "Epoch 20/20\n",
      "Validation Loss: 0.5732, Accuracy: 0.8264, F1-Score: 0.8261\n",
      "Early stopping triggered\n",
      "Best Validation Accuracy: 0.8269\n",
      "제출 파일 생성 완료: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir = './train'\n",
    "test_dir = './test'\n",
    "labels_file = './labels.csv'\n",
    "\n",
    "# 라벨 -> 인덱스 변환 및 반대 변환\n",
    "def create_label_mappings(labels_df):\n",
    "    breed_to_idx = {breed: idx for idx, breed in enumerate(sorted(labels_df['breed'].unique()))}\n",
    "    idx_to_breed = {idx: breed for breed, idx in breed_to_idx.items()}\n",
    "    return breed_to_idx, idx_to_breed\n",
    "\n",
    "# 데이터셋 전처리 변환 설정 (데이터 증강 포함)\n",
    "def get_transforms(augment=False):\n",
    "    if augment:\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(30),  # 회전 범위를 30도로 확대\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.RandomGrayscale(p=0.2),  # 일부 이미지를 흑백으로 변환\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "# Dataset 클래스 정의\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0] + '.jpg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if not self.is_test:\n",
    "            breed_name = self.dataframe.iloc[idx, 1]\n",
    "            label = breed_to_idx[breed_name]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, self.dataframe.iloc[idx, 0]\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성 함수\n",
    "def create_data_loaders(train_df, val_df, batch_size, img_dir):\n",
    "    train_dataset = DogBreedDataset(dataframe=train_df, img_dir=img_dir, transform=get_transforms(augment=True))\n",
    "    val_dataset = DogBreedDataset(dataframe=val_df, img_dir=img_dir, transform=get_transforms(augment=False))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# 모델 정의 (드롭아웃 추가)\n",
    "class ModifiedResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResNet50, self).__init__()\n",
    "        self.model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # 드롭아웃 추가\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, early_stop_limit=3, best_model_path='best_model.pth'):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    early_stop_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        # 학습 단계\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # 검증 단계\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # 성능 지표 계산\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')\n",
    "\n",
    "        # 베스트 모델 저장\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            early_stop_count = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f'Best model saved at epoch {epoch+1} with validation accuracy: {accuracy:.4f}')\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "\n",
    "        # 조기 종료 체크\n",
    "        if early_stop_count >= early_stop_limit:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n",
    "\n",
    "# 테스트 데이터셋에 대한 예측\n",
    "def predict_test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predictions.extend(probabilities.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# 제출 파일 생성 함수\n",
    "def create_submission(predictions, idx_to_breed, test_df, output_file='submission.csv'):\n",
    "    predictions_df = pd.DataFrame(predictions, columns=idx_to_breed.values())\n",
    "    predictions_df.insert(0, 'id', test_df['id'])\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    print(f\"제출 파일 생성 완료: {output_file}\")\n",
    "\n",
    "# 메인 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    # 레이블 파일 읽기\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "    \n",
    "    # 라벨 -> 인덱스 변환 및 반대 변환\n",
    "    breed_to_idx, idx_to_breed = create_label_mappings(labels_df)\n",
    "\n",
    "    # 데이터셋 분리 (전체 데이터셋 사용)\n",
    "    train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['breed'], random_state=42)\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader = create_data_loaders(train_df, val_df, batch_size=32, img_dir=train_dir)\n",
    "\n",
    "    # 클래스 가중치 계산\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(labels_df['breed']), y=labels_df['breed'])\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # 사전 훈련된 ResNet50 모델 로드 및 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ModifiedResNet50(num_classes=len(breed_to_idx))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 옵티마이저, 스케줄러 및 손실 함수 설정\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)  # 학습률을 1e-4로 재조정\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-4, steps_per_epoch=len(train_loader), epochs=20)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # 베스트 모델 파일 경로 설정\n",
    "    best_model_path = 'best_model.pth'\n",
    "\n",
    "    # 모델 학습\n",
    "    model, best_acc = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=20, device=device, best_model_path=best_model_path)\n",
    "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    # 테스트 데이터 로드 및 예측\n",
    "    test_df = pd.DataFrame({'id': [f.split('.')[0] for f in os.listdir(test_dir)]})\n",
    "    test_dataset = DogBreedDataset(dataframe=test_df, img_dir=test_dir, transform=get_transforms(augment=False), is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    predictions = predict_test(model, test_loader, device)\n",
    "\n",
    "    # 제출 파일 생성\n",
    "    create_submission(predictions, idx_to_breed, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdf1ai810/miniconda3/envs/module01/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sdf1ai810/miniconda3/envs/module01/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Validation Loss: 1.1568, Accuracy: 0.6851, F1-Score: 0.6730\n",
      "Best model saved at epoch 1 with validation accuracy: 0.6851\n",
      "Epoch 2/20\n",
      "Validation Loss: 0.9097, Accuracy: 0.7252, F1-Score: 0.7192\n",
      "Best model saved at epoch 2 with validation accuracy: 0.7252\n",
      "Epoch 3/20\n",
      "Validation Loss: 0.8307, Accuracy: 0.7443, F1-Score: 0.7387\n",
      "Best model saved at epoch 3 with validation accuracy: 0.7443\n",
      "Epoch 4/20\n",
      "Validation Loss: 0.8329, Accuracy: 0.7457, F1-Score: 0.7432\n",
      "Best model saved at epoch 4 with validation accuracy: 0.7457\n",
      "Epoch 5/20\n",
      "Validation Loss: 0.8282, Accuracy: 0.7565, F1-Score: 0.7535\n",
      "Best model saved at epoch 5 with validation accuracy: 0.7565\n",
      "Epoch 6/20\n",
      "Validation Loss: 0.8334, Accuracy: 0.7560, F1-Score: 0.7528\n",
      "Epoch 7/20\n",
      "Validation Loss: 0.8083, Accuracy: 0.7667, F1-Score: 0.7645\n",
      "Best model saved at epoch 7 with validation accuracy: 0.7667\n",
      "Epoch 8/20\n",
      "Validation Loss: 0.8210, Accuracy: 0.7697, F1-Score: 0.7659\n",
      "Best model saved at epoch 8 with validation accuracy: 0.7697\n",
      "Epoch 9/20\n",
      "Validation Loss: 0.8121, Accuracy: 0.7658, F1-Score: 0.7623\n",
      "Epoch 10/20\n",
      "Validation Loss: 0.8144, Accuracy: 0.7628, F1-Score: 0.7599\n",
      "Epoch 11/20\n",
      "Validation Loss: 1.2102, Accuracy: 0.6802, F1-Score: 0.6793\n",
      "Early stopping triggered\n",
      "Best Validation Accuracy: 0.7697\n",
      "제출 파일 생성 완료: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import copy\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir = './train'\n",
    "test_dir = './test'\n",
    "labels_file = './labels.csv'\n",
    "\n",
    "# 라벨 -> 인덱스 변환 및 반대 변환\n",
    "def create_label_mappings(labels_df):\n",
    "    breed_to_idx = {breed: idx for idx, breed in enumerate(sorted(labels_df['breed'].unique()))}\n",
    "    idx_to_breed = {idx: breed for breed, idx in breed_to_idx.items()}\n",
    "    return breed_to_idx, idx_to_breed\n",
    "\n",
    "# 데이터셋 전처리 변환 설정 (데이터 증강 제거)\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# Dataset 클래스 정의\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0] + '.jpg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if not self.is_test:\n",
    "            breed_name = self.dataframe.iloc[idx, 1]\n",
    "            label = breed_to_idx[breed_name]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, self.dataframe.iloc[idx, 0]\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성 함수\n",
    "def create_data_loaders(train_df, val_df, batch_size, img_dir):\n",
    "    train_dataset = DogBreedDataset(dataframe=train_df, img_dir=img_dir, transform=get_transforms())\n",
    "    val_dataset = DogBreedDataset(dataframe=val_df, img_dir=img_dir, transform=get_transforms())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# EfficientNet 모델 정의\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        self.model = efficientnet_b0(pretrained=True)  # EfficientNet-B0 사용\n",
    "        num_ftrs = self.model.classifier[1].in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, early_stop_limit=3, best_model_path='best_model.pth'):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    early_stop_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        # 학습 단계\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # 검증 단계\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # 성능 지표 계산\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}')\n",
    "\n",
    "        # 베스트 모델 저장\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            early_stop_count = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f'Best model saved at epoch {epoch+1} with validation accuracy: {accuracy:.4f}')\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "\n",
    "        # 스케줄러 업데이트\n",
    "        scheduler.step()\n",
    "\n",
    "        # 조기 종료 체크\n",
    "        if early_stop_count >= early_stop_limit:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n",
    "\n",
    "# 테스트 데이터셋에 대한 예측\n",
    "def predict_test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predictions.extend(probabilities.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# 제출 파일 생성 함수\n",
    "def create_submission(predictions, idx_to_breed, test_df, output_file='submission.csv'):\n",
    "    predictions_df = pd.DataFrame(predictions, columns=idx_to_breed.values())\n",
    "    predictions_df.insert(0, 'id', test_df['id'])\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    print(f\"제출 파일 생성 완료: {output_file}\")\n",
    "\n",
    "# 메인 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    # 레이블 파일 읽기\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "    \n",
    "    # 라벨 -> 인덱스 변환 및 반대 변환\n",
    "    breed_to_idx, idx_to_breed = create_label_mappings(labels_df)\n",
    "\n",
    "    # 데이터셋 분리 (전체 데이터셋 사용)\n",
    "    train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['breed'], random_state=42)\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader = create_data_loaders(train_df, val_df, batch_size=32, img_dir=train_dir)\n",
    "\n",
    "    # 클래스 가중치 계산\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(labels_df['breed']), y=labels_df['breed'])\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    # EfficientNet 모델 로드 및 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = EfficientNetModel(num_classes=len(breed_to_idx))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 옵티마이저, 스케줄러 및 손실 함수 설정\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-4)  # EfficientNet에 맞춘 학습률 설정\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)  # 스케줄러 적용\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # 베스트 모델 파일 경로 설정\n",
    "    best_model_path = 'best_efficientnet_model.pth'\n",
    "\n",
    "    # 모델 학습\n",
    "    model, best_acc = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=20, device=device, best_model_path=best_model_path)\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_acc:.4f}')\n",
    "\n",
    "    # 테스트 데이터 로드 및 예측\n",
    "    test_df = pd.DataFrame({'id': [f.split('.')[0] for f in os.listdir(test_dir)]})\n",
    "    test_dataset = DogBreedDataset(dataframe=test_df, img_dir=test_dir, transform=get_transforms(), is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    predictions = predict_test(model, test_loader, device)\n",
    "\n",
    "    # 제출 파일 생성\n",
    "    create_submission(predictions, idx_to_breed, test_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
